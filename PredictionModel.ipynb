{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improting Relevant Laibraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('HousePricing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>313000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1340</td>\n",
       "      <td>7912</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1340</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>2005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2384000.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3650</td>\n",
       "      <td>9050</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3370</td>\n",
       "      <td>280</td>\n",
       "      <td>1921</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>342000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1930</td>\n",
       "      <td>11947</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1930</td>\n",
       "      <td>0</td>\n",
       "      <td>1966</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>420000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2000</td>\n",
       "      <td>8030</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1963</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>550000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1940</td>\n",
       "      <td>10500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1140</td>\n",
       "      <td>800</td>\n",
       "      <td>1976</td>\n",
       "      <td>1992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       price  bedrooms  bathrooms  sqft_living  sqft_lot  floors  view  \\\n",
       "0   313000.0         3       1.50         1340      7912     1.5     0   \n",
       "1  2384000.0         5       2.50         3650      9050     2.0     4   \n",
       "2   342000.0         3       2.00         1930     11947     1.0     0   \n",
       "3   420000.0         3       2.25         2000      8030     1.0     0   \n",
       "4   550000.0         4       2.50         1940     10500     1.0     0   \n",
       "\n",
       "   condition  sqft_above  sqft_basement  yr_built  yr_renovated  \n",
       "0          3        1340              0      1955          2005  \n",
       "1          5        3370            280      1921             0  \n",
       "2          4        1930              0      1966             0  \n",
       "3          4        1000           1000      1963             0  \n",
       "4          4        1140            800      1976          1992  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.600000e+03</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4.600000e+03</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "      <td>4600.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.519630e+05</td>\n",
       "      <td>3.400870</td>\n",
       "      <td>2.160815</td>\n",
       "      <td>2139.346957</td>\n",
       "      <td>1.485252e+04</td>\n",
       "      <td>1.512065</td>\n",
       "      <td>0.240652</td>\n",
       "      <td>3.451739</td>\n",
       "      <td>1827.265435</td>\n",
       "      <td>312.081522</td>\n",
       "      <td>1970.786304</td>\n",
       "      <td>808.608261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.638347e+05</td>\n",
       "      <td>0.908848</td>\n",
       "      <td>0.783781</td>\n",
       "      <td>963.206916</td>\n",
       "      <td>3.588444e+04</td>\n",
       "      <td>0.538288</td>\n",
       "      <td>0.778405</td>\n",
       "      <td>0.677230</td>\n",
       "      <td>862.168977</td>\n",
       "      <td>464.137228</td>\n",
       "      <td>29.731848</td>\n",
       "      <td>979.414536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>370.000000</td>\n",
       "      <td>6.380000e+02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>370.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1900.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.228750e+05</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>5.000750e+03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1951.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.609435e+05</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>1980.000000</td>\n",
       "      <td>7.683000e+03</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1590.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1976.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.549625e+05</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2620.000000</td>\n",
       "      <td>1.100125e+04</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2300.000000</td>\n",
       "      <td>610.000000</td>\n",
       "      <td>1997.000000</td>\n",
       "      <td>1999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.659000e+07</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13540.000000</td>\n",
       "      <td>1.074218e+06</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>9410.000000</td>\n",
       "      <td>4820.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              price     bedrooms    bathrooms   sqft_living      sqft_lot  \\\n",
       "count  4.600000e+03  4600.000000  4600.000000   4600.000000  4.600000e+03   \n",
       "mean   5.519630e+05     3.400870     2.160815   2139.346957  1.485252e+04   \n",
       "std    5.638347e+05     0.908848     0.783781    963.206916  3.588444e+04   \n",
       "min    0.000000e+00     0.000000     0.000000    370.000000  6.380000e+02   \n",
       "25%    3.228750e+05     3.000000     1.750000   1460.000000  5.000750e+03   \n",
       "50%    4.609435e+05     3.000000     2.250000   1980.000000  7.683000e+03   \n",
       "75%    6.549625e+05     4.000000     2.500000   2620.000000  1.100125e+04   \n",
       "max    2.659000e+07     9.000000     8.000000  13540.000000  1.074218e+06   \n",
       "\n",
       "            floors         view    condition   sqft_above  sqft_basement  \\\n",
       "count  4600.000000  4600.000000  4600.000000  4600.000000    4600.000000   \n",
       "mean      1.512065     0.240652     3.451739  1827.265435     312.081522   \n",
       "std       0.538288     0.778405     0.677230   862.168977     464.137228   \n",
       "min       1.000000     0.000000     1.000000   370.000000       0.000000   \n",
       "25%       1.000000     0.000000     3.000000  1190.000000       0.000000   \n",
       "50%       1.500000     0.000000     3.000000  1590.000000       0.000000   \n",
       "75%       2.000000     0.000000     4.000000  2300.000000     610.000000   \n",
       "max       3.500000     4.000000     5.000000  9410.000000    4820.000000   \n",
       "\n",
       "          yr_built  yr_renovated  \n",
       "count  4600.000000   4600.000000  \n",
       "mean   1970.786304    808.608261  \n",
       "std      29.731848    979.414536  \n",
       "min    1900.000000      0.000000  \n",
       "25%    1951.000000      0.000000  \n",
       "50%    1976.000000      0.000000  \n",
       "75%    1997.000000   1999.000000  \n",
       "max    2014.000000   2014.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('price', axis = 1)\n",
    "y = df['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Teat Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4600,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling The Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train) \n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.65556839,  0.11045493,  0.99117383, ..., -0.67927447,\n",
       "        -0.0362029 , -0.83278755],\n",
       "       [-0.4402218 ,  0.42934156,  0.57777853, ..., -0.67927447,\n",
       "         1.4118153 ,  1.12756409],\n",
       "       [-1.53601199, -1.48397821, -1.26660048, ..., -0.67927447,\n",
       "        -2.02301855,  1.16018565],\n",
       "       ...,\n",
       "       [ 0.65556839, -0.20843169,  0.52477914, ..., -0.67927447,\n",
       "        -0.6086752 ,  1.18872951],\n",
       "       [-0.4402218 , -0.52731832, -0.85320519, ..., -0.67927447,\n",
       "         0.90669267,  1.21217625],\n",
       "       [ 1.75135858,  2.0237747 ,  3.38674658, ...,  3.17350147,\n",
       "         1.17609141, -0.83278755]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3450, 11), (1150, 11))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/125\n",
      "87/87 - 1s - loss: 562540.3125 - val_loss: 526167.1875\n",
      "Epoch 2/125\n",
      "87/87 - 0s - loss: 513050.1875 - val_loss: 343757.2812\n",
      "Epoch 3/125\n",
      "87/87 - 0s - loss: 263627.8438 - val_loss: 207063.3906\n",
      "Epoch 4/125\n",
      "87/87 - 0s - loss: 211886.5469 - val_loss: 188940.3906\n",
      "Epoch 5/125\n",
      "87/87 - 0s - loss: 195150.6250 - val_loss: 180769.4531\n",
      "Epoch 6/125\n",
      "87/87 - 0s - loss: 186911.0000 - val_loss: 175528.3281\n",
      "Epoch 7/125\n",
      "87/87 - 0s - loss: 182669.9375 - val_loss: 171787.6250\n",
      "Epoch 8/125\n",
      "87/87 - 0s - loss: 179543.3750 - val_loss: 168995.6406\n",
      "Epoch 9/125\n",
      "87/87 - 0s - loss: 177241.4531 - val_loss: 166507.7656\n",
      "Epoch 10/125\n",
      "87/87 - 0s - loss: 175846.1719 - val_loss: 164572.9219\n",
      "Epoch 11/125\n",
      "87/87 - 0s - loss: 174589.0938 - val_loss: 162932.5469\n",
      "Epoch 12/125\n",
      "87/87 - 0s - loss: 173828.8750 - val_loss: 161875.5781\n",
      "Epoch 13/125\n",
      "87/87 - 0s - loss: 173143.5781 - val_loss: 161358.5469\n",
      "Epoch 14/125\n",
      "87/87 - 0s - loss: 173084.1250 - val_loss: 159891.6094\n",
      "Epoch 15/125\n",
      "87/87 - 0s - loss: 171938.2500 - val_loss: 159203.2656\n",
      "Epoch 16/125\n",
      "87/87 - 0s - loss: 171417.1406 - val_loss: 158161.7344\n",
      "Epoch 17/125\n",
      "87/87 - 0s - loss: 170884.5469 - val_loss: 158464.1562\n",
      "Epoch 18/125\n",
      "87/87 - 0s - loss: 170740.5000 - val_loss: 157041.3906\n",
      "Epoch 19/125\n",
      "87/87 - 0s - loss: 170511.8906 - val_loss: 156640.3438\n",
      "Epoch 20/125\n",
      "87/87 - 0s - loss: 170379.1250 - val_loss: 156181.8125\n",
      "Epoch 21/125\n",
      "87/87 - 0s - loss: 170091.9375 - val_loss: 156094.5156\n",
      "Epoch 22/125\n",
      "87/87 - 0s - loss: 169889.9062 - val_loss: 155650.1562\n",
      "Epoch 23/125\n",
      "87/87 - 0s - loss: 170522.0469 - val_loss: 155343.4531\n",
      "Epoch 24/125\n",
      "87/87 - 0s - loss: 169644.4375 - val_loss: 155658.0625\n",
      "Epoch 25/125\n",
      "87/87 - 0s - loss: 169578.4219 - val_loss: 155037.5625\n",
      "Epoch 26/125\n",
      "87/87 - 0s - loss: 169504.1719 - val_loss: 155180.7188\n",
      "Epoch 27/125\n",
      "87/87 - 0s - loss: 169578.8594 - val_loss: 154785.7812\n",
      "Epoch 28/125\n",
      "87/87 - 0s - loss: 169513.4219 - val_loss: 154688.7969\n",
      "Epoch 29/125\n",
      "87/87 - 0s - loss: 169326.4531 - val_loss: 154837.0625\n",
      "Epoch 30/125\n",
      "87/87 - 0s - loss: 169084.4062 - val_loss: 154464.9219\n",
      "Epoch 31/125\n",
      "87/87 - 0s - loss: 169122.7656 - val_loss: 154082.5000\n",
      "Epoch 32/125\n",
      "87/87 - 0s - loss: 169104.9375 - val_loss: 154674.0469\n",
      "Epoch 33/125\n",
      "87/87 - 0s - loss: 169070.5156 - val_loss: 154100.7812\n",
      "Epoch 34/125\n",
      "87/87 - 0s - loss: 169055.3594 - val_loss: 153922.2188\n",
      "Epoch 35/125\n",
      "87/87 - 0s - loss: 168966.8438 - val_loss: 154036.4375\n",
      "Epoch 36/125\n",
      "87/87 - 0s - loss: 168872.4375 - val_loss: 153875.2188\n",
      "Epoch 37/125\n",
      "87/87 - 0s - loss: 168789.9531 - val_loss: 154018.3125\n",
      "Epoch 38/125\n",
      "87/87 - 0s - loss: 168506.9531 - val_loss: 153731.0469\n",
      "Epoch 39/125\n",
      "87/87 - 0s - loss: 168902.4844 - val_loss: 153482.7188\n",
      "Epoch 40/125\n",
      "87/87 - 0s - loss: 168726.8750 - val_loss: 153889.2812\n",
      "Epoch 41/125\n",
      "87/87 - 0s - loss: 168497.1875 - val_loss: 154066.9062\n",
      "Epoch 42/125\n",
      "87/87 - 0s - loss: 168551.6406 - val_loss: 153486.4531\n",
      "Epoch 43/125\n",
      "87/87 - 0s - loss: 168420.1094 - val_loss: 153676.4219\n",
      "Epoch 44/125\n",
      "87/87 - 0s - loss: 168640.3438 - val_loss: 153259.3750\n",
      "Epoch 45/125\n",
      "87/87 - 0s - loss: 168404.4375 - val_loss: 153523.2656\n",
      "Epoch 46/125\n",
      "87/87 - 0s - loss: 168382.5000 - val_loss: 153286.4219\n",
      "Epoch 47/125\n",
      "87/87 - 0s - loss: 168389.1875 - val_loss: 153178.2031\n",
      "Epoch 48/125\n",
      "87/87 - 0s - loss: 168387.9844 - val_loss: 153450.1250\n",
      "Epoch 49/125\n",
      "87/87 - 0s - loss: 168144.2344 - val_loss: 153532.6562\n",
      "Epoch 50/125\n",
      "87/87 - 0s - loss: 168364.1094 - val_loss: 153111.2188\n",
      "Epoch 51/125\n",
      "87/87 - 0s - loss: 168263.7344 - val_loss: 153071.8438\n",
      "Epoch 52/125\n",
      "87/87 - 0s - loss: 168378.7969 - val_loss: 153524.1719\n",
      "Epoch 53/125\n",
      "87/87 - 0s - loss: 168005.8438 - val_loss: 153356.9219\n",
      "Epoch 54/125\n",
      "87/87 - 0s - loss: 167979.8438 - val_loss: 153352.7812\n",
      "Epoch 55/125\n",
      "87/87 - 0s - loss: 168309.9375 - val_loss: 153602.0469\n",
      "Epoch 56/125\n",
      "87/87 - 0s - loss: 168302.9062 - val_loss: 153290.2656\n",
      "Epoch 57/125\n",
      "87/87 - 0s - loss: 168254.0469 - val_loss: 153490.1562\n",
      "Epoch 58/125\n",
      "87/87 - 0s - loss: 168097.3750 - val_loss: 153252.3281\n",
      "Epoch 59/125\n",
      "87/87 - 0s - loss: 168044.0156 - val_loss: 152795.5781\n",
      "Epoch 60/125\n",
      "87/87 - 0s - loss: 168147.2969 - val_loss: 153067.0312\n",
      "Epoch 61/125\n",
      "87/87 - 0s - loss: 168191.3438 - val_loss: 153029.8125\n",
      "Epoch 62/125\n",
      "87/87 - 0s - loss: 167900.7188 - val_loss: 153221.4219\n",
      "Epoch 63/125\n",
      "87/87 - 0s - loss: 167957.8750 - val_loss: 153144.2969\n",
      "Epoch 64/125\n",
      "87/87 - 0s - loss: 168244.8750 - val_loss: 153229.5625\n",
      "Epoch 65/125\n",
      "87/87 - 0s - loss: 167937.7812 - val_loss: 153190.8125\n",
      "Epoch 66/125\n",
      "87/87 - 0s - loss: 168055.2344 - val_loss: 153058.8750\n",
      "Epoch 67/125\n",
      "87/87 - 0s - loss: 168038.6719 - val_loss: 153095.9375\n",
      "Epoch 68/125\n",
      "87/87 - 0s - loss: 167817.7344 - val_loss: 153114.0000\n",
      "Epoch 69/125\n",
      "87/87 - 0s - loss: 167719.5781 - val_loss: 153159.3750\n",
      "Epoch 70/125\n",
      "87/87 - 0s - loss: 168275.0312 - val_loss: 153029.6094\n",
      "Epoch 71/125\n",
      "87/87 - 0s - loss: 167795.5625 - val_loss: 153192.5625\n",
      "Epoch 72/125\n",
      "87/87 - 0s - loss: 167542.4531 - val_loss: 153215.2656\n",
      "Epoch 73/125\n",
      "87/87 - 0s - loss: 167749.1406 - val_loss: 153329.4531\n",
      "Epoch 74/125\n",
      "87/87 - 0s - loss: 167652.5156 - val_loss: 153334.1875\n",
      "Epoch 75/125\n",
      "87/87 - 0s - loss: 167725.2031 - val_loss: 153270.6719\n",
      "Epoch 76/125\n",
      "87/87 - 0s - loss: 167857.5625 - val_loss: 153112.0781\n",
      "Epoch 77/125\n",
      "87/87 - 0s - loss: 167624.1406 - val_loss: 153288.2656\n",
      "Epoch 78/125\n",
      "87/87 - 0s - loss: 167469.4531 - val_loss: 152962.3125\n",
      "Epoch 79/125\n",
      "87/87 - 0s - loss: 167626.3438 - val_loss: 153030.8125\n",
      "Epoch 80/125\n",
      "87/87 - 0s - loss: 167769.4375 - val_loss: 153194.7812\n",
      "Epoch 81/125\n",
      "87/87 - 0s - loss: 167476.7812 - val_loss: 153039.5625\n",
      "Epoch 82/125\n",
      "87/87 - 0s - loss: 167902.0000 - val_loss: 152990.0469\n",
      "Epoch 83/125\n",
      "87/87 - 0s - loss: 167790.2344 - val_loss: 152931.1719\n",
      "Epoch 84/125\n",
      "87/87 - 0s - loss: 167670.8125 - val_loss: 153125.2188\n",
      "Epoch 85/125\n",
      "87/87 - 0s - loss: 167467.0312 - val_loss: 152963.5156\n",
      "Epoch 86/125\n",
      "87/87 - 0s - loss: 167643.3438 - val_loss: 152742.5781\n",
      "Epoch 87/125\n",
      "87/87 - 0s - loss: 167401.2188 - val_loss: 152768.8125\n",
      "Epoch 88/125\n",
      "87/87 - 0s - loss: 167367.4375 - val_loss: 152726.3438\n",
      "Epoch 89/125\n",
      "87/87 - 0s - loss: 167518.7656 - val_loss: 153072.7031\n",
      "Epoch 90/125\n",
      "87/87 - 0s - loss: 167363.9844 - val_loss: 153572.5938\n",
      "Epoch 91/125\n",
      "87/87 - 0s - loss: 167866.3594 - val_loss: 153066.7969\n",
      "Epoch 92/125\n",
      "87/87 - 0s - loss: 167615.3594 - val_loss: 153069.1875\n",
      "Epoch 93/125\n",
      "87/87 - 0s - loss: 167423.8438 - val_loss: 153299.8906\n",
      "Epoch 94/125\n",
      "87/87 - 0s - loss: 167323.1562 - val_loss: 153846.6875\n",
      "Epoch 95/125\n",
      "87/87 - 0s - loss: 167320.4531 - val_loss: 153436.7031\n",
      "Epoch 96/125\n",
      "87/87 - 0s - loss: 167156.1875 - val_loss: 153270.5781\n",
      "Epoch 97/125\n",
      "87/87 - 0s - loss: 167638.0469 - val_loss: 153071.4844\n",
      "Epoch 98/125\n",
      "87/87 - 0s - loss: 167113.9688 - val_loss: 154622.6719\n",
      "Epoch 99/125\n",
      "87/87 - 0s - loss: 167340.5156 - val_loss: 153570.6250\n",
      "Epoch 100/125\n",
      "87/87 - 0s - loss: 167565.7344 - val_loss: 153163.1875\n",
      "Epoch 101/125\n",
      "87/87 - 0s - loss: 167443.4688 - val_loss: 153040.7500\n",
      "Epoch 102/125\n",
      "87/87 - 0s - loss: 167138.1719 - val_loss: 153262.5625\n",
      "Epoch 103/125\n",
      "87/87 - 0s - loss: 167500.8594 - val_loss: 152859.6094\n",
      "Epoch 104/125\n",
      "87/87 - 0s - loss: 167136.4375 - val_loss: 153195.4219\n",
      "Epoch 105/125\n",
      "87/87 - 0s - loss: 167170.0469 - val_loss: 154367.3438\n",
      "Epoch 106/125\n",
      "87/87 - 0s - loss: 167329.1250 - val_loss: 152827.4375\n",
      "Epoch 107/125\n",
      "87/87 - 0s - loss: 168058.4219 - val_loss: 154254.4062\n",
      "Epoch 108/125\n",
      "87/87 - 0s - loss: 167682.4219 - val_loss: 153693.4062\n",
      "Epoch 109/125\n",
      "87/87 - 0s - loss: 167664.5469 - val_loss: 153917.4219\n",
      "Epoch 110/125\n",
      "87/87 - 0s - loss: 167143.4844 - val_loss: 153207.3906\n",
      "Epoch 111/125\n",
      "87/87 - 0s - loss: 166976.2031 - val_loss: 153369.1094\n",
      "Epoch 112/125\n",
      "87/87 - 0s - loss: 167162.2344 - val_loss: 152973.8125\n",
      "Epoch 113/125\n",
      "87/87 - 0s - loss: 167003.4688 - val_loss: 153152.0156\n",
      "Epoch 114/125\n",
      "87/87 - 0s - loss: 167048.7344 - val_loss: 153414.6875\n",
      "Epoch 115/125\n",
      "87/87 - 0s - loss: 167267.6250 - val_loss: 152994.9531\n",
      "Epoch 116/125\n",
      "87/87 - 0s - loss: 167325.7344 - val_loss: 153184.9219\n",
      "Epoch 117/125\n",
      "87/87 - 0s - loss: 167254.1406 - val_loss: 152915.1719\n",
      "Epoch 118/125\n",
      "87/87 - 0s - loss: 167296.5781 - val_loss: 153003.0469\n",
      "Epoch 119/125\n",
      "87/87 - 0s - loss: 167109.8438 - val_loss: 152910.3594\n",
      "Epoch 120/125\n",
      "87/87 - 0s - loss: 167138.6250 - val_loss: 152960.4688\n",
      "Epoch 121/125\n",
      "87/87 - 0s - loss: 166895.8438 - val_loss: 153091.8438\n",
      "Epoch 122/125\n",
      "87/87 - 0s - loss: 167104.6875 - val_loss: 153008.8125\n",
      "Epoch 123/125\n",
      "87/87 - 0s - loss: 167218.4062 - val_loss: 153177.9062\n",
      "Epoch 124/125\n",
      "87/87 - 0s - loss: 167008.2500 - val_loss: 153315.7344\n",
      "Epoch 125/125\n",
      "87/87 - 0s - loss: 166965.2344 - val_loss: 152859.3438\n"
     ]
    }
   ],
   "source": [
    "input_size=11\n",
    "output_size=1\n",
    "\n",
    "model=tf.keras.Sequential([\n",
    "    \n",
    "                            \n",
    "                            tf.keras.layers.Dense(11,activation='softplus'),\n",
    "    \n",
    "                            tf.keras.layers.Dense(128,activation='softplus'),\n",
    "                            tf.keras.layers.Dense(64,activation='softplus'),\n",
    "                            tf.keras.layers.Dense(64,activation='softplus'),\n",
    "                            tf.keras.layers.Dense(10,activation='softplus'),\n",
    "                            tf.keras.layers.Dense(1,activation='softplus')\n",
    "                    \n",
    "                        ])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),loss=('mean_absolute_error'))\n",
    "\n",
    "\n",
    "history=model.fit(X_train_scaled, y_train, epochs=125, validation_split = 0.2,verbose=2)\n",
    "hist  = pd.DataFrame(history.history)\n",
    "hist['epoch'] = history.epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph shows us that we are not overfitting since validation loss is always less than the training loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction on test DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values are:  [[828730.3 ]\n",
      " [568139.75]\n",
      " [412124.34]\n",
      " [675294.94]\n",
      " [276230.8 ]]\n",
      "Real values are:  2899    600000.0\n",
      "61      459990.0\n",
      "1627    399000.0\n",
      "202     562000.0\n",
      "2374    405000.0\n",
      "Name: price, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test_scaled[:5])\n",
    "print(\"Predicted values are: \", predictions)\n",
    "print(\"Real values are: \", y_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 0s 1ms/step - loss: 156347.6719\n",
      "Mean absolute error from neural net:  156347.671875\n"
     ]
    }
   ],
   "source": [
    "mae_neural = model.evaluate(X_test_scaled, y_test)\n",
    "print('Mean absolute error from neural net: ', mae_neural)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error from linear regression:  162463.5442164709\n"
     ]
    }
   ],
   "source": [
    "lr_model = linear_model.LinearRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test_scaled)\n",
    "mae_lr = mean_absolute_error(y_test, y_pred_lr)\n",
    "print('Mean absolute error from linear regression: ', mae_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error using decision tree:  227765.6481497391\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeRegressor()\n",
    "tree.fit(X_train_scaled, y_train)\n",
    "y_pred_tree = tree.predict(X_test_scaled)\n",
    "mae_dt = mean_absolute_error(y_test, y_pred_tree)\n",
    "print('Mean absolute error using decision tree: ', mae_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest.\n",
    "#Increasing the number of tress and seeing the effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_estimators=30, random_state=30)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "model = RandomForestRegressor(n_estimators = 30, random_state=30)\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_RF = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error Using Random Forest:  171133.57828058646\n"
     ]
    }
   ],
   "source": [
    "mae_RF = mean_absolute_error(y_test, y_pred_RF)\n",
    "print('Mean absolute error Using Random Forest: ', mae_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features by Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sqft_living      0.361767\n",
      "sqft_lot         0.182554\n",
      "yr_built         0.145491\n",
      "bathrooms        0.079503\n",
      "sqft_above       0.075857\n",
      "condition        0.043626\n",
      "bedrooms         0.029093\n",
      "yr_renovated     0.024353\n",
      "sqft_basement    0.021691\n",
      "floors           0.018902\n",
      "view             0.017163\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "feature_list = list(X.columns)\n",
    "feature_imp = pd.Series(model.feature_importances_, index=feature_list).sort_values(ascending=False)\n",
    "print(feature_imp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
